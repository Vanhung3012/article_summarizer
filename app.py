import streamlit as st
import google.generativeai as genai
import aiohttp
import asyncio
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import time
from tenacity import retry, stop_after_attempt, wait_exponential
import base64
from io import BytesIO
from PIL import Image

def check_api_key():
    """
    Ki·ªÉm tra API key Gemini
    """
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        if not api_key:
            st.error("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY!")
            st.stop()
        return api_key
    except Exception as e:
        st.error("‚ö†Ô∏è GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh trong Streamlit Secrets!")
        st.stop()

def validate_url(url):
    """
    Ki·ªÉm tra URL h·ª£p l·ªá
    """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

class NewsArticleGenerator:
    def __init__(self):
        self.gemini_api_key = check_api_key()
        genai.configure(api_key=self.gemini_api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    async def fetch_url(self, url):
        """
        ƒê·ªçc n·ªôi dung t·ª´ URL
        """
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(url) as response:
                    return await response.text()
        except Exception as e:
            raise Exception(f"L·ªói khi ƒë·ªçc URL {url}: {str(e)}")

    async def fetch_image(self, url):
        """
        T·∫£i ·∫£nh t·ª´ URL
        """
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(url) as response:
                    if response.status == 200:
                        return await response.read()
                    return None
        except:
            return None

    def extract_content(self, html):
        """
        Tr√≠ch xu·∫•t n·ªôi dung v√† h√¨nh ·∫£nh t·ª´ HTML
        """
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # Lo·∫°i b·ªè c√°c ph·∫ßn kh√¥ng c·∫ßn thi·∫øt
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'iframe', 'aside']):
                tag.decompose()
            
            # L·∫•y ti√™u ƒë·ªÅ
            title = ""
            if soup.find('h1'):
                title = soup.find('h1').get_text().strip()
            elif soup.find('title'):
                title = soup.find('title').get_text().strip()
            
            # L·∫•y n·ªôi dung ch√≠nh
            article_tags = soup.find_all(['article', 'main', 'div'], class_=['content', 'article', 'post'])
            content = ""
            
            if article_tags:
                for tag in article_tags:
                    paragraphs = tag.find_all('p')
                    content += ' '.join([p.get_text().strip() for p in paragraphs])
            else:
                paragraphs = soup.find_all('p')
                content = ' '.join([p.get_text().strip() for p in paragraphs])

            # L·∫•y h√¨nh ·∫£nh
            images = []
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if src and src.startswith('http'):
                    alt = img.get('alt', '')
                    images.append({
                        'url': src,
                        'alt': alt
                    })
            
            return {
                'title': title,
                'content': content,
                'images': images[:3]  # Gi·ªõi h·∫°n 3 ·∫£nh cho m·ªói b√†i
            }
            
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω HTML: {str(e)}")

    async def scrape_articles(self, urls):
        """
        Thu th·∫≠p n·ªôi dung t·ª´ nhi·ªÅu URLs
        """
        articles = []
        for url in urls:
            if url.strip():
                html = await self.fetch_url(url)
                content = self.extract_content(html)
                
                # T·∫£i c√°c h√¨nh ·∫£nh
                images = []
                for img in content['images']:
                    img_data = await self.fetch_image(img['url'])
                    if img_data:
                        images.append({
                            'data': img_data,
                            'alt': img['alt']
                        })
                
                articles.append({
                    'url': url,
                    'title': content['title'],
                    'content': content['content'],
                    'images': images
                })
        return articles

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        reraise=True
    )
    async def call_gemini_api(self, prompt):
        """
        G·ªçi Gemini API v·ªõi retry
        """
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e):
                st.warning("ƒêang ch·ªù API... Vui l√≤ng ƒë·ª£i trong gi√¢y l√°t")
                time.sleep(5)
                raise e
            raise e

    async def generate_article(self, articles):
        """
        T·∫°o b√†i b√°o t·ª´ nhi·ªÅu ngu·ªìn
        """
        try:
            # T·ªïng h·ª£p n·ªôi dung t·ª´ c√°c b√†i b√°o
            combined_content = "\n\n---\n\n".join(
                [f"Ti√™u ƒë·ªÅ: {a['title']}\nN·ªôi dung: {a['content']}" for a in articles]
            )

            # Prompt ƒë·ªÉ ph√¢n t√≠ch v√† t·ªïng h·ª£p th√†nh b√†i b√°o m·ªõi
            analysis_prompt = f"""
            Ph√¢n t√≠ch v√† t·ªïng h·ª£p th√†nh m·ªôt b√†i b√°o m·ªõi t·ª´ c√°c ngu·ªìn sau:

            {combined_content}

            Y√™u c·∫ßu:

            1. Ti√™u ƒë·ªÅ b√†i b√°o:
               - T·ªëi ƒëa 15 t·ª´
               - Thu h√∫t, t·∫°o ·∫•n t∆∞·ª£ng m·∫°nh
               - Ph·∫£n √°nh ch√≠nh x√°c n·ªôi dung ch√≠nh
               - S·ª≠ d·ª•ng t·ª´ ng·ªØ b√°o ch√≠ chu·∫©n m·ª±c
               - Tr√°nh gi·∫≠t g√¢n, c√¢u view

            2. C·∫•u tr√∫c b√†i vi·∫øt:
               - T√≥m t·∫Øt √Ω ch√≠nh trong ƒëo·∫°n m·ªü ƒë·∫ßu (3-4 c√¢u)
               - Tri·ªÉn khai chi ti·∫øt theo logic r√µ r√†ng
               - D·∫´n ngu·ªìn v√† tr√≠ch d·∫´n khi c·∫ßn
               - Ph√¢n t√≠ch, ƒë√°nh gi√° kh√°ch quan
               - K·∫øt lu·∫≠n s√∫c t√≠ch, ƒë·∫ßy ƒë·ªß
               - Ch√®n ch√∫ th√≠ch cho h√¨nh ·∫£nh ph√π h·ª£p v√†o v·ªã tr√≠ th√≠ch h·ª£p trong b√†i vi·∫øt

            3. N·ªôi dung:
               - T·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn
               - ƒê·∫£m b·∫£o t√≠nh ch√≠nh x√°c
               - Cung c·∫•p g√≥c nh√¨n ƒëa chi·ªÅu
               - Th√™m s·ªë li·ªáu, d·ªØ li·ªáu c·ª• th·ªÉ
               - ƒê·ªô d√†i 800-1000 t·ª´

            4. Ng√¥n ng·ªØ:
               - Trong s√°ng, d·ªÖ hi·ªÉu
               - Phong c√°ch b√°o ch√≠ chuy√™n nghi·ªáp
               - Kh√°ch quan, trung l·∫≠p
               - Tr√°nh t·ª´ ng·ªØ c·∫£m x√∫c, thi√™n ki·∫øn
               - Ch·ªçn l·ªçc t·ª´ ng·ªØ ph√π h·ª£p vƒÉn phong

            Format ph·∫£n h·ªìi:
            TITLE: [ti√™u ƒë·ªÅ b√†i b√°o]
            ARTICLE: [n·ªôi dung b√†i b√°o]
            """

            # G·ªçi API ƒë·ªÉ t·∫°o b√†i b√°o
            result = await self.call_gemini_api(analysis_prompt)
            
            try:
                title = result.split('TITLE:')[1].split('ARTICLE:')[0].strip()
                content = result.split('ARTICLE:')[1].strip()
                
                # Ki·ªÉm tra ƒë·ªô d√†i ti√™u ƒë·ªÅ
                if len(title.split()) > 15:
                    optimize_title_prompt = f"""
                    T·ªëi ∆∞u ti√™u ƒë·ªÅ sau ƒë·ªÉ ng·∫Øn g·ªçn h∆°n (t·ªëi ƒëa 15 t·ª´) nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c √Ω ch√≠nh:
                    {title}

                    Y√™u c·∫ßu:
                    - R√∫t g·ªçn nh∆∞ng kh√¥ng m·∫•t √Ω nghƒ©a
                    - V·∫´n ph·∫£i thu h√∫t, ·∫•n t∆∞·ª£ng
                    - D√πng t·ª´ ng·ªØ ch√≠nh x√°c, s√∫c t√≠ch
                    - Ph√π h·ª£p phong c√°ch b√°o ch√≠

                    Format: TITLE: [ti√™u ƒë·ªÅ t·ªëi ∆∞u]
                    """
                    title_result = await self.call_gemini_api(optimize_title_prompt)
                    title = title_result.split('TITLE:')[1].strip()
                
                # Thu th·∫≠p t·∫•t c·∫£ h√¨nh ·∫£nh t·ª´ c√°c b√†i b√°o
                all_images = []
                for article in articles:
                    all_images.extend(article['images'])
                
                return {
                    'title': title,
                    'content': content,
                    'word_count': len(content.split()),
                    'sources': [a['url'] for a in articles],
                    'images': all_images
                }
                
            except Exception as e:
                raise Exception(f"L·ªói khi x·ª≠ l√Ω k·∫øt qu·∫£: {str(e)}")
            
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫°o b√†i b√°o: {str(e)}")

def main():
    st.set_page_config(
        page_title="T·ªïng H·ª£p Tin T·ª©c", 
        page_icon="üì∞",
        layout="wide"
    )
    
    st.title("üì∞ ·ª®ng D·ª•ng T·ªïng H·ª£p Tin T·ª©c")
    st.markdown("""
    ·ª®ng d·ª•ng n√†y gi√∫p t·ªïng h·ª£p v√† vi·∫øt l·∫°i n·ªôi dung t·ª´ nhi·ªÅu b√†i b√°o th√†nh m·ªôt b√†i b√°o m·ªõi, 
    ƒë·∫£m b·∫£o t√≠nh chuy√™n nghi·ªáp v√† ch·∫•t l∆∞·ª£ng.
    """)
    st.markdown("---")

    if 'generator' not in st.session_state:
        st.session_state.generator = NewsArticleGenerator()

    with st.container():
        st.subheader("üîó Nh·∫≠p URLs B√†i B√°o")
        
        # T·∫°o 3 c·ªôt ƒë·ªÉ nh·∫≠p URL
        cols = st.columns(3)
        urls = []
        for i, col in enumerate(cols, 1):
            with col:
                url = st.text_input(
                    f"URL b√†i b√°o {i}",
                    key=f"url{i}",
                    placeholder="https://..."
                )
                urls.append(url)
        
        # N√∫t t·∫°o b√†i b√°o
        if st.button("T·∫°o B√†i B√°o", type="primary"):
            # Ki·ªÉm tra URLs
            valid_urls = [url for url in urls if url.strip()]
            if len(valid_urls) == 0:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p √≠t nh·∫•t m·ªôt URL!")
                return
                
            invalid_urls = [url for url in valid_urls if not validate_url(url)]
            if invalid_urls:
                st.error(f"‚ùå URL kh√¥ng h·ª£p l·ªá: {', '.join(invalid_urls)}")
                return
            
            # Hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh
            progress = st.progress(0)
            status = st.empty()
            
            try:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # Thu th·∫≠p n·ªôi dung
                    status.text("ƒêang ƒë·ªçc n·ªôi dung v√† t·∫£i h√¨nh ·∫£nh t·ª´ c√°c URLs...")
                    progress.progress(25)
                    
                    articles = asyncio.run(
                        st.session_state.generator.scrape_articles(valid_urls)
                    )
                    
                    if not articles:
                        st.error("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung t·ª´ c√°c URLs!")
                        return
                    
                    # T·∫°o b√†i b√°o
                    status.text("ƒêang t·ªïng h·ª£p v√† vi·∫øt b√†i...")
                    progress.progress(50)
                    
                    result = asyncio.run(
                        st.session_state.generator.generate_article(articles)
                    )
                    
                    if result:
                        progress.progress(100)
                        status.empty()
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        st.success(f"‚úÖ ƒê√£ t·∫°o b√†i b√°o th√†nh c√¥ng! ({result['word_count']} t·ª´)")
                        
                        st.markdown(f"## üìå {result['title']}")
                        
                        # Hi·ªÉn th·ªã n·ªôi dung v√† h√¨nh ·∫£nh
                        content_parts = result['content'].split('\n\n')
                        
                        # Ch√®n h√¨nh ·∫£nh v√†o gi·ªØa c√°c ƒëo·∫°n vƒÉn
                        for i, part in enumerate(content_parts):
                            st.write(part)
                            # Ch√®n ·∫£nh sau m·ªói 2-3 ƒëo·∫°n vƒÉn
                            if i % 3 == 1 and result['images'] and len(result['images']) > i//3:
                                img = result['images'][i//3]
                                try:
                                    image = Image.open(BytesIO(img['data']))
                                    st.image(image, caption=img['alt'], use_column_width=True)
                                except Exception as e:
                                    st.warning(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã h√¨nh ·∫£nh: {str(e)}")
                                    # Hi·ªÉn th·ªã ngu·ªìn tham kh·∫£o
                        st.markdown("---")
                        st.markdown("### üìö Ngu·ªìn Tham Kh·∫£o")
                        for url in result['sources']:
                            st.markdown(f"- [{url}]({url})")
                        
                        # T·∫°o n√∫t xu·∫•t b√†i vi·∫øt
                        st.markdown("---")
                        st.subheader("üíæ T·∫£i Xu·ªëng")
                        
                        # T·∫°o n·ªôi dung Markdown
                        markdown_content = f"""# {result['title']}\n\n{result['content']}\n\n---\n### Ngu·ªìn Tham Kh·∫£o\n"""
                        for url in result['sources']:
                            markdown_content += f"- {url}\n"
                        
                        # T·∫°o n·ªôi dung HTML
                        html_content = f"""
                        <!DOCTYPE html>
                        <html>
                        <head>
                            <meta charset="utf-8">
                            <title>{result['title']}</title>
                            <style>
                                body {{
                                    font-family: Arial, sans-serif;
                                    line-height: 1.6;
                                    max-width: 800px;
                                    margin: 0 auto;
                                    padding: 20px;
                                }}
                                img {{
                                    max-width: 100%;
                                    height: auto;
                                    margin: 20px 0;
                                }}
                                .sources {{
                                    margin-top: 40px;
                                    padding-top: 20px;
                                    border-top: 1px solid #ccc;
                                }}
                            </style>
                        </head>
                        <body>
                            <h1>{result['title']}</h1>
                            {result['content'].replace('\n\n', '</p><p>')}
                            <div class="sources">
                                <h3>Ngu·ªìn Tham Kh·∫£o</h3>
                                <ul>
                                    {''.join([f'<li><a href="{url}">{url}</a></li>' for url in result['sources']])}
                                </ul>
                            </div>
                        </body>
                        </html>
                        """
                        
                        col1, col2 = st.columns(2)
                        
                        # N√∫t t·∫£i Markdown
                        with col1:
                            md_bytes = markdown_content.encode()
                            md_b64 = base64.b64encode(md_bytes).decode()
                            md_href = f'data:text/markdown;base64,{md_b64}'
                            st.download_button(
                                "üìù T·∫£i Markdown",
                                markdown_content,
                                "article.md",
                                "text/markdown",
                                use_container_width=True
                            )
                        
                        # N√∫t t·∫£i HTML
                        with col2:
                            html_bytes = html_content.encode()
                            html_b64 = base64.b64encode(html_bytes).decode()
                            html_href = f'data:text/html;base64,{html_b64}'
                            st.download_button(
                                "üåê T·∫£i HTML",
                                html_content,
                                "article.html",
                                "text/html",
                                use_container_width=True
                            )
                            
                    else:
                        st.error("‚ùå Kh√¥ng th·ªÉ t·∫°o b√†i b√°o!")
                        
            except Exception as e:
                st.error(f"‚ùå C√≥ l·ªói x·∫£y ra: {str(e)}")
            finally:
                progress.empty()
                status.empty()

if __name__ == "__main__":
    main()

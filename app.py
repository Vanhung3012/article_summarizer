import streamlit as st
import google.generativeai as genai
import aiohttp
import asyncio
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import time
from tenacity import retry, stop_after_attempt, wait_exponential

def check_api_key():
    """
    Ki·ªÉm tra API key Gemini
    """
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        if not api_key:
            st.error("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY!")
            st.stop()
        return api_key
    except Exception as e:
        st.error("‚ö†Ô∏è GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh trong Streamlit Secrets!")
        st.stop()

def validate_url(url):
    """
    Ki·ªÉm tra URL h·ª£p l·ªá
    """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

class NewsArticleGenerator:
    def __init__(self):
        self.gemini_api_key = check_api_key()
        genai.configure(api_key=self.gemini_api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    async def fetch_url(self, url):
        """
        ƒê·ªçc n·ªôi dung t·ª´ URL
        """
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(url) as response:
                    return await response.text()
        except Exception as e:
            raise Exception(f"L·ªói khi ƒë·ªçc URL {url}: {str(e)}")

    def extract_content(self, html):
        """
        Tr√≠ch xu·∫•t n·ªôi dung t·ª´ HTML
        """
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            # Lo·∫°i b·ªè c√°c ph·∫ßn kh√¥ng c·∫ßn thi·∫øt
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'iframe', 'aside']):
                tag.decompose()
            
            # L·∫•y ti√™u ƒë·ªÅ
            title = ""
            if soup.find('h1'):
                title = soup.find('h1').get_text().strip()
            elif soup.find('title'):
                title = soup.find('title').get_text().strip()
            
            # L·∫•y n·ªôi dung ch√≠nh
            article_tags = soup.find_all(['article', 'main', 'div'], class_=['content', 'article', 'post'])
            content = ""
            
            if article_tags:
                for tag in article_tags:
                    paragraphs = tag.find_all('p')
                    content += ' '.join([p.get_text().strip() for p in paragraphs])
            else:
                # N·∫øu kh√¥ng t√¨m th·∫•y th·∫ª article, l·∫•y t·∫•t c·∫£ th·∫ª p
                paragraphs = soup.find_all('p')
                content = ' '.join([p.get_text().strip() for p in paragraphs])
            
            return {
                'title': title,
                'content': content
            }
            
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω HTML: {str(e)}")

    async def scrape_articles(self, urls):
        """
        Thu th·∫≠p n·ªôi dung t·ª´ nhi·ªÅu URLs
        """
        articles = []
        for url in urls:
            if url.strip():
                html = await self.fetch_url(url)
                content = self.extract_content(html)
                articles.append({
                    'url': url,
                    'title': content['title'],
                    'content': content['content']
                })
        return articles

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        reraise=True
    )
    async def call_gemini_api(self, prompt):
        """
        G·ªçi Gemini API v·ªõi retry
        """
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e):
                st.warning("ƒêang ch·ªù API... Vui l√≤ng ƒë·ª£i trong gi√¢y l√°t")
                time.sleep(5)
                raise e
            raise e

    async def generate_article(self, articles):
        """
        T·∫°o b√†i b√°o t·ª´ nhi·ªÅu ngu·ªìn
        """
        try:
            # T·ªïng h·ª£p n·ªôi dung t·ª´ c√°c b√†i b√°o
            combined_content = "\n\n---\n\n".join(
                [f"Ti√™u ƒë·ªÅ: {a['title']}\nN·ªôi dung: {a['content']}" for a in articles]
            )

            # Prompt ƒë·ªÉ ph√¢n t√≠ch v√† t·ªïng h·ª£p th√†nh b√†i b√°o m·ªõi
            analysis_prompt = f"""
            Ph√¢n t√≠ch v√† t·ªïng h·ª£p th√†nh m·ªôt b√†i b√°o m·ªõi t·ª´ c√°c ngu·ªìn sau:

            {combined_content}

            Y√™u c·∫ßu:

            1. Ti√™u ƒë·ªÅ b√†i b√°o:
               - T·ªëi ƒëa 15 t·ª´
               - Thu h√∫t, t·∫°o ·∫•n t∆∞·ª£ng m·∫°nh
               - Ph·∫£n √°nh ch√≠nh x√°c n·ªôi dung ch√≠nh
               - S·ª≠ d·ª•ng t·ª´ ng·ªØ b√°o ch√≠ chu·∫©n m·ª±c
               - Tr√°nh gi·∫≠t g√¢n, c√¢u view

            2. C·∫•u tr√∫c b√†i vi·∫øt:
               - T√≥m t·∫Øt √Ω ch√≠nh trong ƒëo·∫°n m·ªü ƒë·∫ßu (3-4 c√¢u)
               - Tri·ªÉn khai chi ti·∫øt theo logic r√µ r√†ng
               - D·∫´n ngu·ªìn v√† tr√≠ch d·∫´n khi c·∫ßn
               - Ph√¢n t√≠ch, ƒë√°nh gi√° kh√°ch quan
               - K·∫øt lu·∫≠n s√∫c t√≠ch, ƒë·∫ßy ƒë·ªß

            3. N·ªôi dung:
               - T·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn
               - ƒê·∫£m b·∫£o t√≠nh ch√≠nh x√°c
               - Cung c·∫•p g√≥c nh√¨n ƒëa chi·ªÅu
               - Th√™m s·ªë li·ªáu, d·ªØ li·ªáu c·ª• th·ªÉ
               - ƒê·ªô d√†i 800-1000 t·ª´

            4. Ng√¥n ng·ªØ:
               - Trong s√°ng, d·ªÖ hi·ªÉu
               - Phong c√°ch b√°o ch√≠ chuy√™n nghi·ªáp
               - Kh√°ch quan, trung l·∫≠p
               - Tr√°nh t·ª´ ng·ªØ c·∫£m x√∫c, thi√™n ki·∫øn
               - Ch·ªçn l·ªçc t·ª´ ng·ªØ ph√π h·ª£p vƒÉn phong

            Format ph·∫£n h·ªìi:
            TITLE: [ti√™u ƒë·ªÅ b√†i b√°o]
            ARTICLE: [n·ªôi dung b√†i b√°o]
            """

            # G·ªçi API ƒë·ªÉ t·∫°o b√†i b√°o
            result = await self.call_gemini_api(analysis_prompt)
            
            try:
                title = result.split('TITLE:')[1].split('ARTICLE:')[0].strip()
                content = result.split('ARTICLE:')[1].strip()
                
                # Ki·ªÉm tra ƒë·ªô d√†i ti√™u ƒë·ªÅ
                if len(title.split()) > 15:
                    optimize_title_prompt = f"""
                    T·ªëi ∆∞u ti√™u ƒë·ªÅ sau ƒë·ªÉ ng·∫Øn g·ªçn h∆°n (t·ªëi ƒëa 15 t·ª´) nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c √Ω ch√≠nh:
                    {title}

                    Y√™u c·∫ßu:
                    - R√∫t g·ªçn nh∆∞ng kh√¥ng m·∫•t √Ω nghƒ©a
                    - V·∫´n ph·∫£i thu h√∫t, ·∫•n t∆∞·ª£ng
                    - D√πng t·ª´ ng·ªØ ch√≠nh x√°c, s√∫c t√≠ch
                    - Ph√π h·ª£p phong c√°ch b√°o ch√≠

                    Format: TITLE: [ti√™u ƒë·ªÅ t·ªëi ∆∞u]
                    """
                    title_result = await self.call_gemini_api(optimize_title_prompt)
                    title = title_result.split('TITLE:')[1].strip()
                
                # Ki·ªÉm tra ƒë·ªô d√†i n·ªôi dung
                word_count = len(content.split())
                if word_count < 800:
                    expand_prompt = f"""
                    M·ªü r·ªông n·ªôi dung b√†i b√°o sau ƒë·ªÉ ƒë·∫°t 800-1000 t·ª´.
                    Th√™m chi ti·∫øt, ph√¢n t√≠ch s√¢u h∆°n nh∆∞ng v·∫´n gi·ªØ ƒë∆∞·ª£c t√≠nh m·∫°ch l·∫°c v√† phong c√°ch ban ƒë·∫ßu.

                    B√†i b√°o hi·ªán t·∫°i:
                    {content}
                    """
                    content = await self.call_gemini_api(expand_prompt)
                
                return {
                    'title': title,
                    'content': content,
                    'word_count': len(content.split()),
                    'sources': [a['url'] for a in articles]
                }
                
            except Exception as e:
                raise Exception(f"L·ªói khi x·ª≠ l√Ω k·∫øt qu·∫£: {str(e)}")
            
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫°o b√†i b√°o: {str(e)}")

def main():
    st.set_page_config(
        page_title="T·ªïng H·ª£p Tin T·ª©c", 
        page_icon="üì∞",
        layout="wide"
    )
    
    # Th√™m CSS cho n√∫t copy v√† container
    st.markdown("""
    <style>
    .copy-button {
        position: absolute;
        top: 10px;
        right: 10px;
        padding: 8px 16px;
        background-color: #0066cc;
        color: white;
        border: none;
        border-radius: 4px;
        cursor: pointer;
        font-size: 14px;
        display: flex;
        align-items: center;
        gap: 6px;
        transition: background-color 0.3s;
    }
    .copy-button:hover {
        background-color: #0052a3;
    }
    .copy-button svg {
        width: 16px;
        height: 16px;
    }
    .article-container {
        position: relative;
        padding: 20px;
        background-color: #f8f9fa;
        border-radius: 8px;
        margin: 20px 0;
        border: 1px solid #e9ecef;
    }
    .article-content {
        margin-top: 10px;
        line-height: 1.6;
        white-space: pre-wrap;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Th√™m JavaScript cho ch·ª©c nƒÉng copy
    st.markdown("""
    <script>
    function copyArticleContent() {
        const content = document.querySelector('.article-content').innerText;
        navigator.clipboard.writeText(content).then(() => {
            const button = document.querySelector('.copy-button');
            const originalText = button.innerHTML;
            button.innerHTML = `
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7" />
                </svg>
                ƒê√£ sao ch√©p!
            `;
            setTimeout(() => {
                button.innerHTML = originalText;
            }, 2000);
        });
    }
    </script>
    """, unsafe_allow_html=True)
    
    st.title("üì∞ ·ª®ng D·ª•ng T·ªïng H·ª£p Tin T·ª©c")
    st.markdown("""
    ·ª®ng d·ª•ng n√†y gi√∫p t·ªïng h·ª£p v√† vi·∫øt l·∫°i n·ªôi dung t·ª´ nhi·ªÅu b√†i b√°o th√†nh m·ªôt b√†i b√°o m·ªõi, 
    ƒë·∫£m b·∫£o t√≠nh chuy√™n nghi·ªáp v√† ch·∫•t l∆∞·ª£ng.
    """)
    st.markdown("---")

    if 'generator' not in st.session_state:
        st.session_state.generator = NewsArticleGenerator()

    with st.container():
        st.subheader("üîó Nh·∫≠p URLs B√†i B√°o")
        
        # T·∫°o 3 c·ªôt ƒë·ªÉ nh·∫≠p URL
        cols = st.columns(3)
        urls = []
        for i, col in enumerate(cols, 1):
            with col:
                url = st.text_input(
                    f"URL b√†i b√°o {i}",
                    key=f"url{i}",
                    placeholder="https://..."
                )
                urls.append(url)
        
        # N√∫t t·∫°o b√†i b√°o
        if st.button("T·∫°o B√†i B√°o", type="primary"):
            # Ki·ªÉm tra URLs
            valid_urls = [url for url in urls if url.strip()]
            if len(valid_urls) == 0:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p √≠t nh·∫•t m·ªôt URL!")
                return
                
            invalid_urls = [url for url in valid_urls if not validate_url(url)]
            if invalid_urls:
                st.error(f"‚ùå URL kh√¥ng h·ª£p l·ªá: {', '.join(invalid_urls)}")
                return
            
            # Hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh
            progress = st.progress(0)
            status = st.empty()
            
            try:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    # Thu th·∫≠p n·ªôi dung
                    status.text("ƒêang ƒë·ªçc n·ªôi dung t·ª´ c√°c URLs...")
                    progress.progress(25)
                    
                    articles = asyncio.run(
                        st.session_state.generator.scrape_articles(valid_urls)
                    )
                    
                    if not articles:
                        st.error("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung t·ª´ c√°c URLs!")
                        return
                    
                    # T·∫°o b√†i b√°o
                    status.text("ƒêang t·ªïng h·ª£p v√† vi·∫øt b√†i...")
                    progress.progress(50)
                    
                    result = asyncio.run(
                        st.session_state.generator.generate_article(articles)
                    )
                    
                    if result:
                        progress.progress(100)
                        status.empty()
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ v·ªõi n√∫t copy
                        st.success(f"‚úÖ ƒê√£ t·∫°o b√†i b√°o th√†nh c√¥ng! ({result['word_count']} t·ª´)")
st.markdown(f"## üìå {result['title']}")
                        
                        # Container cho n·ªôi dung b√†i vi·∫øt v·ªõi n√∫t copy
                        st.markdown(f"""
                        <div class="article-container">
                            <button class="copy-button" onclick="copyArticleContent()">
                                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 5H6a2 2 0 00-2 2v12a2 2 0 002 2h10a2 2 0 002-2v-1M8 5a2 2 0 002 2h2a2 2 0 002-2M8 5a2 2 0 012-2h2a2 2 0 012 2m0 0h2a2 2 0 012 2v3m2 4H10m0 0l3-3m-3 3l3 3" />
                                </svg>
                                Sao ch√©p
                            </button>
                            <div class="article-content">
                                {result['content']}
                            </div>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        # Hi·ªÉn th·ªã ngu·ªìn tham kh·∫£o
                        with st.expander("üîç Xem ngu·ªìn b√†i vi·∫øt"):
                            for i, url in enumerate(result['sources'], 1):
                                st.write(f"{i}. [{url}]({url})")
                        
            except Exception as e:
                st.error(f"‚ùå C√≥ l·ªói x·∫£y ra: {str(e)}")
            finally:
                progress.empty()
                status.empty()

if __name__ == "__main__":
    main()

import streamlit as st
import google.generativeai as genai
import aiohttp
import asyncio
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import time
from tenacity import retry, stop_after_attempt, wait_exponential

def check_api_key():
    try:
        api_key = st.secrets["GEMINI_API_KEY"]
        if not api_key:
            st.error("‚ö†Ô∏è Vui l√≤ng c·∫•u h√¨nh GEMINI_API_KEY!")
            st.stop()
        return api_key
    except Exception as e:
        st.error("‚ö†Ô∏è GEMINI_API_KEY ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh trong Streamlit Secrets!")
        st.stop()

def validate_url(url):
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

class NewsArticleGenerator:
    def __init__(self):
        self.gemini_api_key = check_api_key()
        genai.configure(api_key=self.gemini_api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

    async def fetch_url(self, url):
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(url) as response:
                    return await response.text(), url
        except Exception as e:
            raise Exception(f"L·ªói khi ƒë·ªçc URL {url}: {str(e)}")

    def extract_content(self, html, url):
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'iframe', 'aside']):
                tag.decompose()

            title = ""
            if soup.find('h1'):
                title = soup.find('h1').get_text().strip()
            elif soup.find('title'):
                title = soup.find('title').get_text().strip()

            images = []
            for img in soup.find_all('img'):
                src = img.get('src', '')
                if src:
                    if src.startswith('//'):
                        src = 'https:' + src
                    elif src.startswith('/'):
                        parsed_url = urlparse(url)
                        src = f"{parsed_url.scheme}://{parsed_url.netloc}{src}"
                    
                    if not any(x in src.lower() for x in ['avatar', 'logo', 'icon', 'ads', 'banner']):
                        alt = img.get('alt', '')
                        if len(src) > 10 and src.startswith(('http://', 'https://')):
                            images.append({
                                'src': src,
                                'alt': alt
                            })

            article_tags = soup.find_all(['article', 'main', 'div'], class_=['content', 'article', 'post'])
            content = ""
            
            if article_tags:
                for tag in article_tags:
                    paragraphs = tag.find_all('p')
                    content += ' '.join([p.get_text().strip() for p in paragraphs])
            else:
                paragraphs = soup.find_all('p')
                content = ' '.join([p.get_text().strip() for p in paragraphs])

            return {
                'title': title,
                'content': content,
                'images': images[:5],
                'url': url
            }
            
        except Exception as e:
            raise Exception(f"L·ªói khi x·ª≠ l√Ω HTML: {str(e)}")

    async def scrape_articles(self, urls):
        articles = []
        tasks = [self.fetch_url(url) for url in urls if url.strip()]
        results = await asyncio.gather(*tasks)
        
        for html, url in results:
            content = self.extract_content(html, url)
            articles.append(content)
        return articles

    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))
    async def call_gemini_api(self, prompt):
        try:
            response = self.model.generate_content(prompt)
            return response.text
        except Exception as e:
            if "429" in str(e):
                st.warning("ƒêang ch·ªù API... Vui l√≤ng ƒë·ª£i trong gi√¢y l√°t")
                time.sleep(5)
                raise e
            raise e

    async def generate_article(self, articles):
        try:
            combined_content = "\n\n---\n\n".join(
                [f"Ti√™u ƒë·ªÅ: {a['title']}\nN·ªôi dung: {a['content']}\nH√¨nh ·∫£nh: {', '.join([img['alt'] for img in a['images']])}" 
                 for a in articles]
            )

            analysis_prompt = f"""
            Ph√¢n t√≠ch v√† t·ªïng h·ª£p th√†nh m·ªôt b√†i b√°o m·ªõi t·ª´ c√°c ngu·ªìn sau:

            {combined_content}

            Y√™u c·∫ßu:

            1. Ti√™u ƒë·ªÅ b√†i b√°o:
               - T·ªëi ƒëa 15 t·ª´
               - Thu h√∫t, t·∫°o ·∫•n t∆∞·ª£ng m·∫°nh
               - Ph·∫£n √°nh ch√≠nh x√°c n·ªôi dung ch√≠nh
               - S·ª≠ d·ª•ng t·ª´ ng·ªØ b√°o ch√≠ chu·∫©n m·ª±c
               - Tr√°nh gi·∫≠t g√¢n, c√¢u view

            2. C·∫•u tr√∫c b√†i vi·∫øt:
               - T√≥m t·∫Øt √Ω ch√≠nh trong ƒëo·∫°n m·ªü ƒë·∫ßu (3-4 c√¢u)
               - Tri·ªÉn khai chi ti·∫øt theo logic r√µ r√†ng
               - D·∫´n ngu·ªìn v√† tr√≠ch d·∫´n khi c·∫ßn
               - Ph√¢n t√≠ch, ƒë√°nh gi√° kh√°ch quan
               - K·∫øt lu·∫≠n s√∫c t√≠ch, ƒë·∫ßy ƒë·ªß

            3. N·ªôi dung:
               - T·ªïng h·ª£p th√¥ng tin t·ª´ nhi·ªÅu ngu·ªìn
               - ƒê·∫£m b·∫£o t√≠nh ch√≠nh x√°c
               - Cung c·∫•p g√≥c nh√¨n ƒëa chi·ªÅu
               - Th√™m s·ªë li·ªáu, d·ªØ li·ªáu c·ª• th·ªÉ
               - ƒê·ªô d√†i 800-1000 t·ª´

            4. Ng√¥n ng·ªØ:
               - Trong s√°ng, d·ªÖ hi·ªÉu
               - Phong c√°ch b√°o ch√≠ chuy√™n nghi·ªáp
               - Kh√°ch quan, trung l·∫≠p
               - Tr√°nh t·ª´ ng·ªØ c·∫£m x√∫c, thi√™n ki·∫øn
               - Ch·ªçn l·ªçc t·ª´ ng·ªØ ph√π h·ª£p vƒÉn phong

            5. X·ª≠ l√Ω h√¨nh ·∫£nh:
               - Ch·ªçn t·ªëi ƒëa 5 h√¨nh ·∫£nh ph√π h·ª£p
               - S·∫Øp x·∫øp theo th·ª© t·ª± quan tr·ªçng
               - Vi·∫øt ch√∫ th√≠ch cho m·ªói h√¨nh
               - ƒê·∫£m b·∫£o t√≠nh li√™n quan v√† ch·∫•t l∆∞·ª£ng

            Format ph·∫£n h·ªìi:
            TITLE: [ti√™u ƒë·ªÅ b√†i b√°o]
            ARTICLE: [n·ªôi dung b√†i b√°o]
            IMAGES: [danh s√°ch index h√¨nh ·∫£nh ƒë∆∞·ª£c ch·ªçn v√† ch√∫ th√≠ch m·ªõi]
            """

            result = await self.call_gemini_api(analysis_prompt)
            
            title = result.split('TITLE:')[1].split('ARTICLE:')[0].strip()
            content = result.split('ARTICLE:')[1].split('IMAGES:')[0].strip()
            image_selections = result.split('IMAGES:')[1].strip().split('\n')

            selected_images = []
            all_images = []
            for article in articles:
                all_images.extend(article['images'])

            for selection in image_selections:
                if ':' in selection:
                    idx, caption = selection.split(':', 1)
                    try:
                        idx = int(idx.strip())
                        if 0 <= idx < len(all_images):
                            image = all_images[idx].copy()
                            image['caption'] = caption.strip()
                            selected_images.append(image)
                    except ValueError:
                        continue

            return {
                'title': title,
                'content': content,
                'images': selected_images[:5],
                'word_count': len(content.split()),
                'sources': [a['url'] for a in articles]
            }
        except Exception as e:
            raise Exception(f"L·ªói khi t·∫°o b√†i b√°o: {str(e)}")

def main():
    st.set_page_config(
        page_title="T·ªïng H·ª£p Tin T·ª©c",
        page_icon="üì∞",
        layout="wide"
    )
    
    st.title("üì∞ ·ª®ng D·ª•ng T·ªïng H·ª£p Tin T·ª©c")
    st.markdown("""
    ·ª®ng d·ª•ng t·ªïng h·ª£p v√† vi·∫øt l·∫°i n·ªôi dung t·ª´ nhi·ªÅu b√†i b√°o th√†nh m·ªôt b√†i b√°o m·ªõi,
    k√®m theo h√¨nh ·∫£nh minh h·ªça.
    """)
    st.markdown("---")

    if 'generator' not in st.session_state:
        st.session_state.generator = NewsArticleGenerator()

    with st.container():
        st.subheader("üîó Nh·∫≠p URLs B√†i B√°o")
        
        cols = st.columns(3)
        urls = []
        for i, col in enumerate(cols, 1):
            with col:
                url = st.text_input(
                    f"URL b√†i b√°o {i}",
                    key=f"url{i}",
                    placeholder="https://..."
                )
                urls.append(url)
        
        if st.button("T·∫°o B√†i B√°o", type="primary"):
            valid_urls = [url for url in urls if url.strip()]
            if len(valid_urls) == 0:
                st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p √≠t nh·∫•t m·ªôt URL!")
                return
                
            invalid_urls = [url for url in valid_urls if not validate_url(url)]
            if invalid_urls:
                st.error(f"‚ùå URL kh√¥ng h·ª£p l·ªá: {', '.join(invalid_urls)}")
                return
            
            progress = st.progress(0)
            status = st.empty()
            
            try:
                with st.spinner("ƒêang x·ª≠ l√Ω..."):
                    status.text("ƒêang ƒë·ªçc n·ªôi dung t·ª´ c√°c URLs...")
                    progress.progress(25)
                    
                    articles = asyncio.run(
                        st.session_state.generator.scrape_articles(valid_urls)
                    )
                    
                    if not articles:
                        st.error("‚ùå Kh√¥ng th·ªÉ ƒë·ªçc n·ªôi dung t·ª´ c√°c URLs!")
                        return
                    
                    status.text("ƒêang t·ªïng h·ª£p v√† vi·∫øt b√†i...")
                    progress.progress(50)
                    
                    result = asyncio.run(
                        st.session_state.generator.generate_article(articles)
                    )
                    
                    if result:
                        progress.progress(100)
                        status.empty()
                        
                        st.success(f"‚úÖ ƒê√£ t·∫°o b√†i b√°o th√†nh c√¥ng! ({result['word_count']} t·ª´)")
                        
                        st.markdown(f"## üìå {result['title']}")
                        
                        if result['images']:
                            st.image(
                                result['images'][0]['src'],
                                caption=result['images'][0].get('caption', ''),
                                use_column_width=True
                            )
                        
                        st.markdown("### üìÑ N·ªôi dung")
                        st.write(result['content'])
                        
                        if len(result['images']) > 1:
                            st.markdown("### üñºÔ∏è H√¨nh ·∫£nh li√™n quan")
                            cols = st.columns(2)
                            for i, img in enumerate(result['images'][1:], 1):
                                with cols[i % 2]:
                                    st.image(
                                        img['src'],
                                        caption=img.get('caption', ''),
                                        use_column_width=True
                                    )
                        
                        with st.expander("üîç Xem ngu·ªìn b√†i vi·∫øt"):
                            for i, url in enumerate(result['sources'], 1):
                                st.write(f"{i}. [{url}]({url})")
                        
            except Exception as e:
                st.error(f"‚ùå C√≥ l·ªói x·∫£y ra: {str(e)}")
            finally:
                progress.empty()
                status.empty()

if __name__ == "__main__":
    main()

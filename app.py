import streamlit as st
import google.generativeai as genai
import aiohttp
import asyncio
import newspaper
from concurrent.futures import ThreadPoolExecutor
from urllib.parse import urlparse
import time
import os
import nltk
import ssl

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Download required NLTK data
try:
    nltk.data.find('punkt')
except LookupError:
    nltk.download('punkt')

class ArticleSummarizer:
    def __init__(self):
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not self.gemini_api_key:
            raise ValueError("Kh√¥ng t√¨m th·∫•y GEMINI_API_KEY trong bi·∫øn m√¥i tr∆∞·ªùng")
        genai.configure(api_key=self.gemini_api_key)
        self.model = genai.GenerativeModel('gemini-pro')
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }

    async def fetch_url(self, url):
        """
        ƒê·ªçc URL b·∫•t ƒë·ªìng b·ªô s·ª≠ d·ª•ng aiohttp
        """
        try:
            async with aiohttp.ClientSession(headers=self.headers) as session:
                async with session.get(url) as response:
                    return await response.text()
        except Exception as e:
            raise Exception(f"L·ªói khi ƒë·ªçc URL {url}: {str(e)}")

    def parse_article(self, html, url):
        """
        S·ª≠ d·ª•ng newspaper3k ƒë·ªÉ parse n·ªôi dung b√†i b√°o
        """
        try:
            article = newspaper.Article(url)
            article.download(input_html=html)
            article.parse()
            return {
                'title': article.title,
                'text': article.text
            }
        except Exception as e:
            raise Exception(f"L·ªói khi parse b√†i b√°o: {str(e)}")

    async def extract_content_from_url(self, url):
        """
        Tr√≠ch xu·∫•t n·ªôi dung t·ª´ URL v·ªõi t·ªëi ∆∞u t·ªëc ƒë·ªô
        """
        html = await self.fetch_url(url)
        with ThreadPoolExecutor() as executor:
            article_content = await asyncio.get_event_loop().run_in_executor(
                executor, 
                self.parse_article, 
                html, 
                url
            )
        return article_content['text']

    async def process_urls(self, urls):
        """
        X·ª≠ l√Ω nhi·ªÅu URLs ƒë·ªìng th·ªùi
        """
        try:
            start_time = time.time()
            
            # ƒê·ªçc n·ªôi dung t·ª´ t·∫•t c·∫£ URLs ƒë·ªìng th·ªùi
            contents = await asyncio.gather(
                *[self.extract_content_from_url(url.strip()) for url in urls]
            )
            
            # K·∫øt h·ª£p n·ªôi dung
            combined_content = "\n\n---\n\n".join(contents)
            
            print(f"Th·ªùi gian ƒë·ªçc URLs: {time.time() - start_time:.2f} gi√¢y")
            
            # X·ª≠ l√Ω v·ªõi Gemini
            result = await self.process_content(combined_content)
            
            print(f"T·ªïng th·ªùi gian x·ª≠ l√Ω: {time.time() - start_time:.2f} gi√¢y")
            
            return {
                **result,
                'original_urls': urls
            }
                
        except Exception as e:
            raise Exception(f"L·ªói: {str(e)}")

    async def process_content(self, content):
        """
        X·ª≠ l√Ω n·ªôi dung v·ªõi Gemini v√† ƒë·∫£m b·∫£o ƒë·ªô d√†i t·ªëi thi·ªÉu
        """
        try:
            # B∆∞·ªõc 1: T√≥m t·∫Øt v√† t·∫°o ti√™u ƒë·ªÅ ti·∫øng Anh
            english_prompt = f"""
            Please process this Vietnamese text:
            1. Translate to English
            2. Create a summary (500-1000 words)
            3. Generate a title that captures the main theme
            
            Format your response exactly as:
            TITLE: [your title]
            SUMMARY: [your summary]

            Text to process: {content}
            """
            
            english_response = self.model.generate_content(english_prompt)
            english_result = english_response.text
            
            # Parse k·∫øt qu·∫£ ti·∫øng Anh
            try:
                en_title = english_result.split('TITLE:')[1].split('SUMMARY:')[0].strip()
                en_summary = english_result.split('SUMMARY:')[1].strip()
                
                # Ki·ªÉm tra ƒë·ªô d√†i c·ªßa b·∫£n t√≥m t·∫Øt (t√≠nh theo s·ªë t·ª´)
                word_count = len(en_summary.split())
                
                # N·∫øu d∆∞·ªõi 500 t·ª´, y√™u c·∫ßu Gemini m·ªü r·ªông n·ªôi dung
                if word_count < 500:
                    expand_prompt = f"""
                    The current summary is too short ({word_count} words). 
                    Please expand this summary to be between 500-1000 words by:
                    1. Adding more detailed analysis
                    2. Including relevant context and background information
                    3. Providing more specific examples and explanations
                    4. Elaborating on key points
                    
                    Current summary:
                    {en_summary}
                    """
                    
                    expand_response = self.model.generate_content(expand_prompt)
                    en_summary = expand_response.text
                    
                    # Ki·ªÉm tra l·∫°i ƒë·ªô d√†i sau khi m·ªü r·ªông
                    new_word_count = len(en_summary.split())
                    print(f"ƒê√£ m·ªü r·ªông n·ªôi dung t·ª´ {word_count} t·ª´ l√™n {new_word_count} t·ª´")
                
            except Exception as e:
                raise Exception(f"Kh√¥ng th·ªÉ parse k·∫øt qu·∫£ ti·∫øng Anh: {str(e)}")
            
            # B∆∞·ªõc 2: D·ªãch sang ti·∫øng Vi·ªát
            vietnamese_prompt = f"""
            Translate this English title and summary to Vietnamese.
            Ensure the translation maintains the detailed and comprehensive nature of the content.
            
            Format your response exactly as:
            TITLE: [Vietnamese title]
            SUMMARY: [Vietnamese summary]

            English text:
            TITLE: {en_title}
            SUMMARY: {en_summary}
            """
            
            vietnamese_response = self.model.generate_content(vietnamese_prompt)
            vietnamese_result = vietnamese_response.text
            
            # Parse k·∫øt qu·∫£ ti·∫øng Vi·ªát
            try:
                vi_title = vietnamese_result.split('TITLE:')[1].split('SUMMARY:')[0].strip()
                vi_summary = vietnamese_result.split('SUMMARY:')[1].strip()
                
                # Th√™m th√¥ng tin v·ªÅ ƒë·ªô d√†i v√†o k·∫øt qu·∫£
                word_count_vi = len(vi_summary.split())
                print(f"ƒê·ªô d√†i b·∫£n d·ªãch ti·∫øng Vi·ªát: {word_count_vi} t·ª´")
                
            except Exception as e:
                raise Exception(f"Kh√¥ng th·ªÉ parse k·∫øt qu·∫£ ti·∫øng Vi·ªát: {str(e)}")
            
            return {
                'title': vi_title,
                'content': vi_summary,
                'english_title': en_title,
                'english_summary': en_summary,
                'word_count': word_count_vi  # Th√™m th√¥ng tin v·ªÅ s·ªë t·ª´
            }
            
        except Exception as e:
            raise Exception(f"L·ªói x·ª≠ l√Ω Gemini: {str(e)}")

def validate_url(url):
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except:
        return False

async def process_and_update_ui(summarizer, urls):
    try:
        result = await summarizer.process_urls(urls)
        return result
    except Exception as e:
        raise e

def main():
    st.set_page_config(page_title="·ª®ng d·ª•ng T√≥m t·∫Øt VƒÉn b·∫£n", page_icon="üìù", layout="wide")
    
    st.title("üìù ·ª®ng d·ª•ng T√≥m t·∫Øt Nhi·ªÅu B√†i B√°o")
    st.markdown("---")

    if 'summarizer' not in st.session_state:
        st.session_state.summarizer = ArticleSummarizer()

    with st.container():
        st.subheader("üîó Nh·∫≠p URL c√°c b√†i b√°o")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            url1 = st.text_input("URL b√†i b√°o 1", key="url1")
        with col2:
            url2 = st.text_input("URL b√†i b√°o 2", key="url2")
        with col3:
            url3 = st.text_input("URL b√†i b√°o 3", key="url3")
        
        urls = [url1, url2, url3]
        
        if st.button("T√≥m t·∫Øt", type="primary"):
            if not all(urls):
                st.warning("Vui l√≤ng nh·∫≠p ƒë·ªß 3 URLs!")
                return
            
            invalid_urls = [url for url in urls if not validate_url(url)]
            if invalid_urls:
                st.error(f"C√°c URLs sau kh√¥ng h·ª£p l·ªá: {', '.join(invalid_urls)}")
                return
            
            progress_text = "ƒêang x·ª≠ l√Ω..."
            progress_bar = st.progress(0, text=progress_text)
            
            try:
                result = asyncio.run(process_and_update_ui(st.session_state.summarizer, urls))
                
                if result:
                    progress_bar.progress(100, text="Ho√†n th√†nh!")
                    st.success(f"‚úÖ T√≥m t·∫Øt th√†nh c√¥ng! (ƒê·ªô d√†i: {result['word_count']} t·ª´)")
                    
                    st.markdown(f"## üìå {result['title']}")
                    st.markdown("### üìÑ B·∫£n t√≥m t·∫Øt")
                    st.write(result['content'])
                    
                    with st.expander("Xem phi√™n b·∫£n ti·∫øng Anh"):
                        st.markdown(f"### {result['english_title']}")
                        st.write(result['english_summary'])
                    
                    with st.expander("Xem URLs g·ªëc"):
                        for i, url in enumerate(result['original_urls'], 1):
                            st.markdown(f"B√†i {i}: [{url}]({url})")
                            
            except Exception as e:
                st.error(f"C√≥ l·ªói x·∫£y ra: {str(e)}")
            finally:
                progress_bar.empty()

if __name__ == "__main__":
    main()
